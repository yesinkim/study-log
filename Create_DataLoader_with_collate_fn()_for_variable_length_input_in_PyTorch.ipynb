{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create DataLoader with collate_fn() for variable-length input in PyTorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLg4kFhlLjT+kcs/d9oJgm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://androidkt.com/create-dataloader-with-collate_fn-for-variable-length-input-in-pytorch/\n",
        "\n",
        "실습코드"
      ],
      "metadata": {
        "id": "5jtFLE7YXh6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "6SmJg71YXrBe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews=['No man is an island','Entire of itself',\n",
        "'Every man is a piece of the continent','part of the main',\n",
        "'If a clod be washed away by the sea','Europe is the less',\n",
        "'As well as if a promontory were','As well as if a manor of thy friend',\n",
        "'Or of thine own were','Any man’s death diminishes me',\n",
        "'Because I am involved in mankind',\n",
        "'And therefore never send to know for whom the bell tolls',\n",
        "'It tolls for thee']\n",
        "\n",
        "\n",
        "labels=[random.randint(0, 1) for i in range(13)]\n",
        "\n",
        "dataset=list(zip(reviews,labels))\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')  \n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "  for text,label in data_iter:\n",
        "    yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(iter(dataset)), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))"
      ],
      "metadata": {
        "id": "_x5mb8QyXlqp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkvgeAVkYdLk",
        "outputId": "3440a269-23fc-4f69-f671-bf6c6cddeeaf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('No man is an island', 1),\n",
              " ('Entire of itself', 0),\n",
              " ('Every man is a piece of the continent', 0),\n",
              " ('part of the main', 0),\n",
              " ('If a clod be washed away by the sea', 1),\n",
              " ('Europe is the less', 1),\n",
              " ('As well as if a promontory were', 1),\n",
              " ('As well as if a manor of thy friend', 0),\n",
              " ('Or of thine own were', 0),\n",
              " ('Any man’s death diminishes me', 1),\n",
              " ('Because I am involved in mankind', 1),\n",
              " ('And therefore never send to know for whom the bell tolls', 1),\n",
              " ('It tolls for thee', 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "  \n",
        "  label_list, text_list, = [], []\n",
        "  \n",
        "  for (_text,_label) in batch:\n",
        "    label_list.append(_label)\n",
        "    processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "  \n",
        "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "  \n",
        "  text_list = pad_sequence(text_list, batch_first=True, padding_value=0)\n",
        "  \n",
        "  return text_list.to(device),label_list.to(device),\n"
      ],
      "metadata": {
        "id": "Ou2nRMkZYjMU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collate_batch(dataset)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFyuyZSkZAw5",
        "outputId": "f4c5fafa-9249-48f8-93ce-6a81f42b7023"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[43,  8,  6, 13, 32,  0,  0,  0,  0,  0,  0],\n",
              "        [25,  1, 34,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [27,  8,  6,  3, 47,  1,  2, 22,  0,  0,  0],\n",
              "        [46,  1,  2, 37,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 5,  3, 21, 17, 56, 16, 20,  2, 49,  0,  0],\n",
              "        [26,  6,  2, 36,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 4, 10,  4,  5,  3, 48, 11,  0,  0,  0,  0],\n",
              "        [ 4, 10,  4,  5,  3, 39,  1, 54, 28,  0,  0],\n",
              "        [44,  1, 53, 45, 11,  0,  0,  0,  0,  0,  0],\n",
              "        [15, 40, 23, 24, 41,  0,  0,  0,  0,  0,  0],\n",
              "        [18, 29, 12, 31, 30, 38,  0,  0,  0,  0,  0],\n",
              "        [14, 52, 42, 50, 55, 35,  7, 57,  2, 19,  9],\n",
              "        [33,  9,  7, 51,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(\n",
        "    dataset, \n",
        "    batch_size=2, \n",
        "    collate_fn=collate_batch,\n",
        "    shuffle=True)\n",
        "\n",
        "for x,y in dataloader:\n",
        "  print(x,\"Targets\",y,\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0QGdWcmYuge",
        "outputId": "97d77936-ba9b-4bb5-af07-a47294e8612f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[44,  1, 53, 45, 11,  0,  0,  0],\n",
            "        [27,  8,  6,  3, 47,  1,  2, 22]]) Targets tensor([0, 0]) \n",
            "\n",
            "tensor([[ 5,  3, 21, 17, 56, 16, 20,  2, 49],\n",
            "        [15, 40, 23, 24, 41,  0,  0,  0,  0]]) Targets tensor([1, 1]) \n",
            "\n",
            "tensor([[46,  1,  2, 37,  0,  0,  0],\n",
            "        [ 4, 10,  4,  5,  3, 48, 11]]) Targets tensor([0, 1]) \n",
            "\n",
            "tensor([[18, 29, 12, 31, 30, 38,  0,  0,  0,  0,  0],\n",
            "        [14, 52, 42, 50, 55, 35,  7, 57,  2, 19,  9]]) Targets tensor([1, 1]) \n",
            "\n",
            "tensor([[33,  9,  7, 51],\n",
            "        [26,  6,  2, 36]]) Targets tensor([0, 1]) \n",
            "\n",
            "tensor([[ 4, 10,  4,  5,  3, 39,  1, 54, 28],\n",
            "        [25,  1, 34,  0,  0,  0,  0,  0,  0]]) Targets tensor([0, 0]) \n",
            "\n",
            "tensor([[43,  8,  6, 13, 32]]) Targets tensor([1]) \n",
            "\n"
          ]
        }
      ]
    }
  ]
}