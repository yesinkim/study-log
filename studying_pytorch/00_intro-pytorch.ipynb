{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"안녕하세요. 파이토치에 오신것을 환영합니다. [사이트](https://medium.com/nlplanet/quick-intro-to-pytorch-with-examples-tensor-operations-73298d20c38a)에 있는 글을 정리하면서 실습합니다.","metadata":{}},{"cell_type":"markdown","source":"# What is `PyTorch`\nPyTorch는 torch라이브러리를 기반으로 하는 오픈소스 ML 프레임워크\n- Numpy, SciPy, Cython 같은 라이브러리와 통합\n- CPU, GPU, 병렬 처리 및 분산훈련 지원\n- Tensorboard로 쉽게 공유할 수 있음\n- 다른 ML 프레임워크를 걸쳐 신경망을 저장하고 로드하는 형식인 ONNX(Open Neural Network Exchange) 지원\n\n기본 연산단위는 `tensor`이고 이는 numpy와 비슷하다.","metadata":{}},{"cell_type":"markdown","source":"### 텐서 정의","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:13:19.088815Z","iopub.execute_input":"2022-06-24T08:13:19.089164Z","iopub.status.idle":"2022-06-24T08:13:19.095073Z","shell.execute_reply.started":"2022-06-24T08:13:19.089133Z","shell.execute_reply":"2022-06-24T08:13:19.093944Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# list to tensor\ndata = [[1, 2], [3, 4]]\nx_data = torch.tensor(data)\n\n# numpy array to tensor\nnp_array = np.array(data)\nx_np = torch.from_numpy(np_array)\n\n# x_data form을 따르는 one, rand tensor\nx_ones = torch.ones_like(x_data) \nx_rand = torch.rand_like(x_data, dtype=torch.float) \n\nprint(f\"x_data: \\n {x_data} \\n\")\nprint(f\"x_np: \\n {x_np} \\n\")\nprint(f\"Ones Tensor: \\n {x_ones} \\n\")\nprint(f\"Random Tensor: \\n {x_rand} \\n\")\nx_data == x_np","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:13:19.111181Z","iopub.execute_input":"2022-06-24T08:13:19.111432Z","iopub.status.idle":"2022-06-24T08:13:19.125137Z","shell.execute_reply.started":"2022-06-24T08:13:19.111408Z","shell.execute_reply":"2022-06-24T08:13:19.124072Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"x_data: \n tensor([[1, 2],\n        [3, 4]]) \n\nx_np: \n tensor([[1, 2],\n        [3, 4]]) \n\nOnes Tensor: \n tensor([[1, 1],\n        [1, 1]]) \n\nRandom Tensor: \n tensor([[0.1319, 0.1469],\n        [0.4368, 0.3176]]) \n\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"tensor([[True, True],\n        [True, True]])"},"metadata":{}}]},{"cell_type":"code","source":"# shape으로 tensor를 만들어보겠습니다.\nshape = (2,3,)   # (2,3)이라고 적어도 되는데 (2,3,)으로 적는 것은 특별한 이유가 있는 것일까?\nrand_tensor = torch.rand(shape)\nones_tensor = torch.ones(shape)\nzeros_tensor = torch.zeros(shape)\n\nprint(f\"Random Tensor: \\n {rand_tensor} \\n\")\nprint(f\"Ones Tensor: \\n {ones_tensor} \\n\")\nprint(f\"Zeros Tensor: \\n {zeros_tensor}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:13:19.129197Z","iopub.execute_input":"2022-06-24T08:13:19.130065Z","iopub.status.idle":"2022-06-24T08:13:19.140633Z","shell.execute_reply.started":"2022-06-24T08:13:19.130024Z","shell.execute_reply":"2022-06-24T08:13:19.139653Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Random Tensor: \n tensor([[0.1431, 0.1129, 0.8076],\n        [0.5432, 0.4713, 0.1614]]) \n\nOnes Tensor: \n tensor([[1., 1., 1.],\n        [1., 1., 1.]]) \n\nZeros Tensor: \n tensor([[0., 0., 0.],\n        [0., 0., 0.]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 텐서 특징","metadata":{}},{"cell_type":"markdown","source":"`tensor`의 가장 중요한 특징은 CPU나 GPU같은 accelerator를 설정하는 `device`와 `shape`, `dtype`이 있다.","metadata":{}},{"cell_type":"code","source":"tensor = torch.rand(3, 4)\n\nprint(f\"Shape of tensor: {tensor.shape, tensor.size()}\")\nprint(f\"Datatype of tensor: {tensor.dtype}\")\nprint(f\"Device tensor is stored on: {tensor.device}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:13:19.142972Z","iopub.execute_input":"2022-06-24T08:13:19.143551Z","iopub.status.idle":"2022-06-24T08:13:19.153241Z","shell.execute_reply.started":"2022-06-24T08:13:19.143512Z","shell.execute_reply":"2022-06-24T08:13:19.151697Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Shape of tensor: (torch.Size([3, 4]), torch.Size([3, 4]))\nDatatype of tensor: torch.float32\nDevice tensor is stored on: cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### tensor를 GPU로 옮겨보겠습니다.","metadata":{}},{"cell_type":"code","source":"# 새로 tensor를 정의하지 않고 윗선에서 정의한 텐서를 그대로 사용하겠습니다\n# GPU 사용가능하다면 텐서를 옮겨줄래~?\nif torch.cuda.is_available():\n    tensor = tensor.to(\"cuda\")\n\nprint(f\"Device tensor is stored on: {tensor.device}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:14:02.270170Z","iopub.execute_input":"2022-06-24T08:14:02.270886Z","iopub.status.idle":"2022-06-24T08:14:02.278974Z","shell.execute_reply.started":"2022-06-24T08:14:02.270835Z","shell.execute_reply":"2022-06-24T08:14:02.277564Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Device tensor is stored on: cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 텐서 조작","metadata":{}},{"cell_type":"code","source":"# tensor indexing\ntensor = torch.ones(4, 5)\n\nprint(f\"tensor: \\n{tensor}\\n\")\nprint(f\"First row: \\n{tensor[0]}\\n\")\nprint(f\"First column: \\n{tensor[:, 0]}\\n\")\nprint(f\"Last column: \\n{tensor[:, -1]}\\n\\n\")\n\n\ntensor[:,1] = 0    # 두번째 colmun을 0으로\nprint(f\"updated tensor:\\n {tensor}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:17:38.650764Z","iopub.execute_input":"2022-06-24T08:17:38.651107Z","iopub.status.idle":"2022-06-24T08:17:38.662157Z","shell.execute_reply.started":"2022-06-24T08:17:38.651077Z","shell.execute_reply":"2022-06-24T08:17:38.660839Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"tensor: \ntensor([[1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.]])\n\nFirst row: \ntensor([1., 1., 1., 1., 1.])\n\nFirst column: \ntensor([1., 1., 1., 1.])\n\nLast column: \ntensor([1., 1., 1., 1.])\n\n\nupdated tensor:\n tensor([[1., 0., 1., 1., 1.],\n        [1., 0., 1., 1., 1.],\n        [1., 0., 1., 1., 1.],\n        [1., 0., 1., 1., 1.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# tensor concatenation\ntensor = torch.ones(4, 5)\nt1 = torch.cat([tensor, tensor], dim=1)\nprint(t1)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:20:05.725834Z","iopub.execute_input":"2022-06-24T08:20:05.726417Z","iopub.status.idle":"2022-06-24T08:20:05.737444Z","shell.execute_reply.started":"2022-06-24T08:20:05.726383Z","shell.execute_reply":"2022-06-24T08:20:05.735997Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# transpose와 행렬곱(matrix multiplication)\ny1 = tensor @ tensor.T\ny2 = tensor.matmul(tensor.T)\nprint(y1)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:20:34.050255Z","iopub.execute_input":"2022-06-24T08:20:34.050632Z","iopub.status.idle":"2022-06-24T08:20:34.073348Z","shell.execute_reply.started":"2022-06-24T08:20:34.050601Z","shell.execute_reply":"2022-06-24T08:20:34.072369Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"tensor([[5., 5., 5., 5.],\n        [5., 5., 5., 5.],\n        [5., 5., 5., 5.],\n        [5., 5., 5., 5.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# 연산별(Element-wise) 곱셈\nz1 = tensor * tensor\nz2 = tensor.mul(tensor)\nprint(z1)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:21:17.755691Z","iopub.execute_input":"2022-06-24T08:21:17.756258Z","iopub.status.idle":"2022-06-24T08:21:17.764622Z","shell.execute_reply.started":"2022-06-24T08:21:17.756222Z","shell.execute_reply":"2022-06-24T08:21:17.763366Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"tensor([[1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1.]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## PyTorch 와 Numpy를 비교해보겠습니다.","metadata":{}},{"cell_type":"code","source":"# Numpy CPU\nsize = 1000\nx = np.random.normal(size=(size, size)).astype(np.float32)\n%timeit np.dot(x, x.T)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:22:41.463220Z","iopub.execute_input":"2022-06-24T08:22:41.463626Z","iopub.status.idle":"2022-06-24T08:22:51.090520Z","shell.execute_reply.started":"2022-06-24T08:22:41.463591Z","shell.execute_reply":"2022-06-24T08:22:51.089367Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"11.9 ms ± 1.51 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n","output_type":"stream"}]},{"cell_type":"code","source":"# PyTorch CPU\nsize = 1000\nx = torch.rand(size=(size, size), dtype=torch.float32)\n%timeit x @ x.T\n\n# Pytorch CPU를 사용하는 것이 조금 더 느리다","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:23:31.781355Z","iopub.execute_input":"2022-06-24T08:23:31.782696Z","iopub.status.idle":"2022-06-24T08:23:43.943110Z","shell.execute_reply.started":"2022-06-24T08:23:31.782645Z","shell.execute_reply":"2022-06-24T08:23:43.942075Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"15.2 ms ± 2.05 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n","output_type":"stream"}]},{"cell_type":"code","source":"# PyTorch GPU\nsize = 1000\nx = torch.rand(size=(size, size), dtype=torch.float32)\nx = x.to(\"cuda\")\n%timeit x @ x.T\n\n# 단위가 밀리초에서 마이크로초로 바뀌었음(빨라졌다는 의미입니다)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T08:26:03.551794Z","iopub.execute_input":"2022-06-24T08:26:03.552138Z","iopub.status.idle":"2022-06-24T08:26:31.292581Z","shell.execute_reply.started":"2022-06-24T08:26:03.552111Z","shell.execute_reply":"2022-06-24T08:26:31.291474Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"346 µs ± 113 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}